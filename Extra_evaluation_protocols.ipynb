{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.00      0.00      0.00      4355\n",
      "         gym       0.18      0.38      0.25      5769\n",
      "       happy       0.00      0.00      0.00      3299\n",
      "       night       0.05      0.00      0.00      4814\n",
      "       relax       0.24      0.64      0.35      6262\n",
      "     running       0.18      0.04      0.06      5577\n",
      "         sad       0.42      0.00      0.00      4678\n",
      "      summer       0.19      0.41      0.26      7987\n",
      "        work       0.11      0.00      0.00      4325\n",
      "     workout       0.19      0.19      0.19      4038\n",
      "\n",
      "   micro avg       0.20      0.20      0.20     51104\n",
      "   macro avg       0.16      0.17      0.11     51104\n",
      "weighted avg       0.17      0.20      0.13     51104\n",
      " samples avg       0.20      0.20      0.20     51104\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# load groundtruth (single label + multilabel), probabilities, one hot\n",
    "# load as dataframe\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score,f1_score,accuracy_score, precision_score, recall_score, classification_report, roc_auc_score, \\\n",
    "    hamming_loss\n",
    "import numpy as np\n",
    "\n",
    "LABELS_LIST = ['car', 'gym', 'happy', 'night', 'relax',\n",
    "       'running', 'sad', 'summer', 'work', 'workout']\n",
    "\n",
    "# [TODO] edit paths to match audio experiment output\n",
    "exp_dir = \"/srv/workspace/research/user_based_contexts_tagging/experiments_results/classic_updated_dataset_long/2020-05-08_13-17-43\"\n",
    "our_ground_truth = pd.read_csv(exp_dir+\"/groundtruth_withIDS.csv\")\n",
    "our_predictions=  pd.read_csv(exp_dir+\"/probabilities_withIDS.csv\",)\n",
    "one_hoted_df =  pd.read_csv(exp_dir+\"/one_hoted_withIDS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-output-single-groundtruth Protocol (SO-SG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratio of positive samples</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gym</th>\n",
       "      <td>0.113</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>0.065</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>0.094</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relax</th>\n",
       "      <td>0.122</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running</th>\n",
       "      <td>0.109</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>0.092</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summer</th>\n",
       "      <td>0.156</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workout</th>\n",
       "      <td>0.079</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ratio of positive samples    AUC  Recall  Precision  f1-score\n",
       "car                          0.085  0.545   0.000      0.000     0.000\n",
       "gym                          0.113  0.677   0.378      0.181     0.245\n",
       "happy                        0.065  0.563   0.000      0.000     0.000\n",
       "night                        0.094  0.575   0.000      0.051     0.001\n",
       "relax                        0.122  0.740   0.639      0.241     0.350\n",
       "running                      0.109  0.612   0.039      0.178     0.064\n",
       "sad                          0.092  0.741   0.001      0.417     0.002\n",
       "summer                       0.156  0.577   0.414      0.192     0.262\n",
       "work                         0.085  0.526   0.000      0.105     0.001\n",
       "workout                      0.079  0.717   0.186      0.193     0.189\n",
       "average                      0.100  0.627   0.166      0.156     0.111"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Per label evaluation of single-output-single-groundtruth \n",
    "# Create a dataframe where we keep all the evaluations\n",
    "results_df = pd.DataFrame(columns=LABELS_LIST)\n",
    "results_df.index.astype(str, copy=False)\n",
    "percentage_of_positives_perclass = sum(our_ground_truth.values[:,2:]) / len(our_ground_truth)\n",
    "results_df.loc[0] = percentage_of_positives_perclass\n",
    "results_df.index = ['Ratio of positive samples']\n",
    "\n",
    "# compute additional metrics (AUC,f1,recall,precision)\n",
    "auc_roc_per_label = roc_auc_score(our_ground_truth.values[:,2:], our_predictions.values[:,2:], average=None)\n",
    "precision_perlabel = precision_score(our_ground_truth.values[:,2:], one_hoted_df.values[:,2:], average=None)\n",
    "recall_perlabel = recall_score(our_ground_truth.values[:,2:], one_hoted_df.values[:,2:], average=None)\n",
    "f1_perlabel = f1_score(our_ground_truth.values[:,2:], one_hoted_df.values[:,2:], average=None)\n",
    "\n",
    "results_df = results_df.append(\n",
    "    pd.DataFrame([auc_roc_per_label,recall_perlabel, precision_perlabel, f1_perlabel], columns=LABELS_LIST))\n",
    "results_df.index = ['Ratio of positive samples',\"AUC\", \"Recall\", \"Precision\", \"f1-score\"]\n",
    "results_df['average'] = results_df.mean(numeric_only=True, axis=1)\n",
    "results_df.round(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-output-single-groundtruth Protocol (MO-SG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratio of positive samples</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gym</th>\n",
       "      <td>0.113</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>0.065</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>0.094</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relax</th>\n",
       "      <td>0.122</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running</th>\n",
       "      <td>0.109</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>0.092</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summer</th>\n",
       "      <td>0.156</td>\n",
       "      <td>0.577</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.526</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workout</th>\n",
       "      <td>0.079</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ratio of positive samples    AUC  Recall  Precision  f1-score\n",
       "car                          0.085  0.545   0.973      0.088     0.162\n",
       "gym                          0.113  0.677   0.934      0.137     0.238\n",
       "happy                        0.065  0.563   0.975      0.066     0.124\n",
       "night                        0.094  0.575   0.993      0.095     0.173\n",
       "relax                        0.122  0.740   0.926      0.163     0.277\n",
       "running                      0.109  0.612   0.957      0.118     0.210\n",
       "sad                          0.092  0.741   0.894      0.137     0.237\n",
       "summer                       0.156  0.577   1.000      0.156     0.270\n",
       "work                         0.085  0.526   1.000      0.085     0.156\n",
       "workout                      0.079  0.717   0.913      0.107     0.192\n",
       "average                      0.100  0.627   0.957      0.115     0.204"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Evaluate on multi-label output and single-label grountruth\n",
    "\"\"\"\n",
    "# Create a dataframe where we keep all the evaluations\n",
    "our_predictions=  pd.read_csv(exp_dir+\"/probabilities_withIDS.csv\",)\n",
    "model_output_rounded = np.round(our_predictions.values[:,2:])\n",
    "model_output_rounded = np.clip(model_output_rounded, 0, 1)\n",
    "results_df = pd.DataFrame(columns=LABELS_LIST)\n",
    "results_df.index.astype(str, copy=False)\n",
    "percentage_of_positives_perclass = sum(our_ground_truth.values[:,2:]) / len(our_ground_truth)\n",
    "results_df.loc[0] = percentage_of_positives_perclass\n",
    "results_df.index = ['Ratio of positive samples']\n",
    "\n",
    "# compute additional metrics (AUC,f1,recall,precision)\n",
    "auc_roc_per_label = roc_auc_score(our_ground_truth.values[:,2:], our_predictions.values[:,2:], average=None)\n",
    "precision_perlabel = precision_score(our_ground_truth.values[:,2:], model_output_rounded, average=None)\n",
    "recall_perlabel = recall_score(our_ground_truth.values[:,2:], model_output_rounded, average=None)\n",
    "f1_perlabel = f1_score(our_ground_truth.values[:,2:], model_output_rounded, average=None)\n",
    "\n",
    "results_df = results_df.append(\n",
    "    pd.DataFrame([auc_roc_per_label,recall_perlabel, precision_perlabel, f1_perlabel], columns=LABELS_LIST))\n",
    "results_df.index = ['Ratio of positive samples',\"AUC\", \"Recall\", \"Precision\", \"f1-score\"]\n",
    "results_df['average'] = results_df.mean(numeric_only=True, axis=1)\n",
    "results_df.round(3).T\n",
    "# get plots of confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
